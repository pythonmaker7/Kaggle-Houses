{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5908e02",
   "metadata": {},
   "source": [
    "## GET LIBS + DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70bf15b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c3a61dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3b4ac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.copy()\n",
    "test = df_test.copy()\n",
    "\n",
    "train_objs_num = len(train)\n",
    "dataset = pd.concat(objs=[train, test], axis=0)\n",
    "dataset = pd.get_dummies(dataset)\n",
    "train = copy.copy(dataset[:train_objs_num])\n",
    "test = copy.copy(dataset[train_objs_num:])\n",
    "\n",
    "df = train\n",
    "df_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8dcf0b",
   "metadata": {},
   "source": [
    "##\n",
    "## PREPROCESS PIPELINE\n",
    "\n",
    "1. **ftiakse 2 diaforetika pipelines**\n",
    "2. **apomonwse numerical kai categorical cols**\n",
    "3. **ftiakse 1 pipeline pou enwnei ta num_pipe + cat_pipe me condition na ta kanei apply stis sthles pou prepei**\n",
    "4. **apply pipeline se df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c88ef5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('one-hot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "797d3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes(include=['float64','int64']).columns\n",
    "categorical_columns = df.select_dtypes(include=['object','category']).columns\n",
    "\n",
    "# because SalePrice is the target\n",
    "numerical_columns = numerical_columns.drop('SalePrice', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e4be6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('num', numerical_transformer, numerical_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ],\n",
    "    remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "792f1c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('SalePrice', axis=1)\n",
    "\n",
    "# AN DEN KANW DROP TO SALEPRICE APO NUMERICAL_COLUMNS ERROR\n",
    "X_preprocessed = pipeline.fit_transform(X)\n",
    "y = np.log(df['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ef8156",
   "metadata": {},
   "source": [
    "##\n",
    "## MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d5d3825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a37e17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c332ba3",
   "metadata": {},
   "source": [
    "### chat gpt can create this block\n",
    "1. im using these models\n",
    "2. create parameter grid\n",
    "3. train the grids + produce best results and best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e90dfb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RandomForest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'LinearRegression': {},\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_depth': [None, 10, 100],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [100,200,500],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'max_depth': [3, 6, 10]\n",
    "    }\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aa7be1",
   "metadata": {},
   "source": [
    "### train and tune models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f71931e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Tuning LinearRegression.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Best parameters for LinearRegression are {}\n",
      "Best score for LinearRegression is 6522806961.724952\n",
      "\n",
      "Training and Tuning RandomForest.\n",
      "Best parameters for RandomForest are {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "Best score for RandomForest is 0.15316547438561767\n",
      "\n",
      "Training and Tuning XGBoost.\n",
      "Best parameters for XGBoost are {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "Best score for XGBoost is 0.13691483027194776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grids = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    \n",
    "    print(f'Training and Tuning {model_name}.')\n",
    "    \n",
    "    grids[model_name] = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grids[model_name],\n",
    "        cv=cv,\n",
    "        scoring='neg_mean_squared_error'\n",
    "    )\n",
    "    grids[model_name].fit(X_train, y_train)\n",
    "    best_params = grids[model_name].best_params_\n",
    "    best_score = np.sqrt(-1 * grids[model_name].best_score_)\n",
    "    \n",
    "    print(f'Best parameters for {model_name} are {best_params}')\n",
    "    print(f'Best score for {model_name} is {best_score}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700864e6",
   "metadata": {},
   "source": [
    "\n",
    "**neural network model**\n",
    "1. build it\n",
    "2. print it\n",
    "3. evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b11fc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=MLPRegressor(max_iter=10000, n_iter_no_change=3,\n",
       "                                    random_state=42),\n",
       "             n_jobs=1,\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;],\n",
       "                         &#x27;alpha&#x27;: [0.0001, 0.001, 0.01],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(10,), (10, 10), (10, 10, 10),\n",
       "                                                25],\n",
       "                         &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;invscaling&#x27;,\n",
       "                                           &#x27;adaptive&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;adam&#x27;]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=MLPRegressor(max_iter=10000, n_iter_no_change=3,\n",
       "                                    random_state=42),\n",
       "             n_jobs=1,\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;],\n",
       "                         &#x27;alpha&#x27;: [0.0001, 0.001, 0.01],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(10,), (10, 10), (10, 10, 10),\n",
       "                                                25],\n",
       "                         &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;invscaling&#x27;,\n",
       "                                           &#x27;adaptive&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;adam&#x27;]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(max_iter=10000, n_iter_no_change=3, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(max_iter=10000, n_iter_no_change=3, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=MLPRegressor(max_iter=10000, n_iter_no_change=3,\n",
       "                                    random_state=42),\n",
       "             n_jobs=1,\n",
       "             param_grid={'activation': ['relu', 'tanh'],\n",
       "                         'alpha': [0.0001, 0.001, 0.01],\n",
       "                         'hidden_layer_sizes': [(10,), (10, 10), (10, 10, 10),\n",
       "                                                25],\n",
       "                         'learning_rate': ['constant', 'invscaling',\n",
       "                                           'adaptive'],\n",
       "                         'solver': ['adam']},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "mlp1 = MLPRegressor(\n",
    "    random_state=42,\n",
    "    max_iter=10000,\n",
    "    n_iter_no_change=3,\n",
    "    learning_rate_init=0.001\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(10,), (10, 10), (10, 10, 10), (25)],\n",
    "    'activation': ['relu','tanh'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant','invscaling', 'adaptive']\n",
    "}\n",
    "\n",
    "mlp2 = GridSearchCV(\n",
    "    mlp1,\n",
    "    param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "mlp2.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b63af05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found for Neural Network Model are:\n",
      " {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 25, 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "Best score for Neural Network Model is:  0.24765541460877707\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters found for Neural Network Model are:\\n', mlp2.best_params_)\n",
    "\n",
    "best_score = np.sqrt(-1 * mlp2.best_score_)\n",
    "print('Best score for Neural Network Model is: ', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0875a841",
   "metadata": {},
   "source": [
    "**tsekare ta modela performance sto y_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7302e89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural network:\t\t 0.040837112641202704\n",
      "linear regression:\t 4.767835526919088e+17\n",
      "random forest:\t\t 0.021689077548682243\n",
      "XGBooster:\t\t 0.017681532847905777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('neural network:\\t\\t', mean_squared_error(mlp2.predict(X_test), y_test))\n",
    "print('linear regression:\\t', mean_squared_error(grids['LinearRegression'].predict(X_test), y_test))\n",
    "print('random forest:\\t\\t', mean_squared_error(grids['RandomForest'].predict(X_test), y_test))\n",
    "print('XGBooster:\\t\\t', mean_squared_error(grids['XGBoost'].predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87692ae1",
   "metadata": {},
   "source": [
    "##\n",
    "##\n",
    "##\n",
    "##\n",
    "## FEATURE ENGINEERING\n",
    "### FTIAKSE PREPROCESS PIPELINE KSANA ALLA ME FEATURE ENGINEERING MESA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22090816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def custom_features(df):\n",
    "    \n",
    "    df_out = df.copy()\n",
    "    df_out['PropertyAge'] = df_out['YrSold'] - df_out['YearBuilt']\n",
    "    df_out['TotalSF'] = df_out['TotalBsmtSF'] + df_out['1stFlrSF'] + df_out['2ndFlrSF']\n",
    "    df_out['TotalBath'] = df_out['FullBath'] + 0.5 * df_out['HalfBath'] + df_out['BsmtFullBath'] + 0.5 * df_out['BsmtHalfBath']\n",
    "    df_out['HasRemodeled'] = (df_out['YearRemodAdd'] != df_out['YearBuilt']).astype(object)\n",
    "    df_out['Has2ndFloor'] = (df_out['2ndFlrSF'] > 0).astype(object)\n",
    "    df_out['HasGarage'] = (df_out['GarageArea'] > 0).astype(object)\n",
    "    df_out['YrSold_cat'] = df_out['YrSold'].astype(object)\n",
    "    df_out['MoSold_cat'] = df_out['MoSold'].astype(object)\n",
    "    df_out['YearBuilt_cat'] = df_out['YearBuilt'].astype(object)\n",
    "    df_out['MSSubClass_cat'] = df_out['MSSubClass'].astype(object)\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "feature_engineering_transformer = FunctionTransformer(custom_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c8c279",
   "metadata": {},
   "source": [
    "1. **exw hdh categorical_columns kai numerical_columns kane se aftes append tis extra**\n",
    "2. **ksanaftiaxnw to preprocessor me to ColumnTransformer etsi wste na exei mesa oles tis sthles**\n",
    "3. **vazw sto pipeline kai to FunctionTransformer pou orizei tis sthles. prwta afto sto pipeline giati ekei ftiaxnontai oi nees sthles prwth fora kai meta to preprocessor**\n",
    "4. **kanw apply pipeline se X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d68a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_categoricals = pd.Index(['HasRemodeled', 'Has2ndFloor', 'HasGarage', 'YrSold_cat',\n",
    "                             'MoSold_cat', 'YearBuilt_cat', 'MSSubClass_cat'])\n",
    "extra_numericals = pd.Index(['PropertyAge', 'TotalSF', 'TotalBath'])\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=['float64','int64']).columns.append(extra_numericals)\n",
    "categorical_columns = df.select_dtypes(include=['object','category']).columns.append(extra_categoricals)\n",
    "numerical_columns = numerical_columns.drop('SalePrice', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b80b98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor2 = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('num', numerical_transformer, numerical_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ],\n",
    "    remainder = 'passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "531523bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline(steps=[\n",
    "    ('fe', feature_engineering_transformer),\n",
    "    ('preprocessor2', preprocessor2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19c21ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df.drop('SalePrice', axis=1)\n",
    "y2 = df['SalePrice']\n",
    "y2 = np.log(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1f8b46",
   "metadata": {},
   "source": [
    "oi extra sthles tha prostethoun mesw tou pipeline ston X2_preprocessed\n",
    "\n",
    "ara ston X2 den xreiazetai na tis prosthesw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be484fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_preprocessed = pipeline2.fit_transform(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f6eace3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 442)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_preprocessed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d88797",
   "metadata": {},
   "source": [
    "## MODELLING 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d861e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_preprocessed, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RandomForest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'LinearRegression': {},\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_depth': [None, 10, 100],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [100,200,500],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'max_depth': [3, 6, 10]\n",
    "    }\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13f51ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Tuning LinearRegression.\n",
      "Best parameters for LinearRegression are {}\n",
      "Best score for LinearRegression is 753882840.8963152\n",
      "\n",
      "Training and Tuning RandomForest.\n",
      "Best parameters for RandomForest are {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best score for RandomForest is 0.14825511131098737\n",
      "\n",
      "Training and Tuning XGBoost.\n",
      "Best parameters for XGBoost are {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "Best score for XGBoost is 0.13577082939560242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grids2 = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    \n",
    "    print(f'Training and Tuning {model_name}.')\n",
    "    \n",
    "    grids2[model_name] = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grids[model_name],\n",
    "        cv=cv,\n",
    "        scoring='neg_mean_squared_error'\n",
    "    )\n",
    "    grids2[model_name].fit(X2_train, y2_train)\n",
    "    best_params2 = grids2[model_name].best_params_\n",
    "    best_score2 = np.sqrt(-1 * grids2[model_name].best_score_)\n",
    "    \n",
    "    print(f'Best parameters for {model_name} are {best_params2}')\n",
    "    print(f'Best score for {model_name} is {best_score2}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a9dc26",
   "metadata": {},
   "source": [
    "## EVALUATE 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de3b661e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression:\t 1.87142927643744e+16\n",
      "random forest:\t\t 0.021569842324804966\n",
      "XGBooster:\t\t 0.018420174398776336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#print('neural network:\\t\\t', mean_squared_error(mlp2.predict(X2_test), y2_test))\n",
    "print('linear regression:\\t', mean_squared_error(grids2['LinearRegression'].predict(X2_test), y2_test))\n",
    "print('random forest:\\t\\t', mean_squared_error(grids2['RandomForest'].predict(X2_test), y2_test))\n",
    "print('XGBooster:\\t\\t', mean_squared_error(grids2['XGBoost'].predict(X2_test), y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "056aa403",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_preprocessed = pipeline2.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ac22181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xqboost submission\n",
    "y_xgboost = grids2['XGBoost'].predict(df_test_preprocessed)\n",
    "# giati htan log prin to kse-logarw\n",
    "y_xgboost = np.exp(y_xgboost)\n",
    "\n",
    "df_xgboost_out = df_test[['Id']].copy()\n",
    "df_xgboost_out ['SalePrice'] = y_xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d311df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit\n",
    "df_xgboost_out.to_csv('../data/submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
